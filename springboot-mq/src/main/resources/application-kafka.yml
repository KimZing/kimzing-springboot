spring:
  kafka:
    bootstrap-servers: 127.0.0.1:9092
    producer:
      # key和value的序列化方式
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: com.kimzing.mq.kafka.serializer.config.MyStringSerializer
      # 重试次数
      retries: 1
      # 服务端应何时ack， 0: partition leader收到还没落盘时就返回  1: leader接收到并且落盘后返回(默认) -1：leader和follower全部落盘后返回
      acks: -1
      # 批量发送消息的数量
      batch-size: 500
      # producer相关的属性
      properties:
        # 定义拦截器
        interceptor:
          classes: com.kimzing.mq.kafka.interceptor.config.MyInterceptor
        # 即使消息没有到达指定数量，也会在超过5ms时进行发送
        linger:
          ms: 5
        # 生产者是否开启幂等去重的功能，当开启幂等的时候，要求acks必须为等待全部
        enable:
          idempotence: true
      # 生产者可用于缓冲等待发送到服务器的记录的总内存大小。
      buffer-memory: 33554432
      # 当该值非空时，开启事物（先关闭，实验事物时需要打开）
#      transaction-id-prefix: transaction_
    consumer:
      # key和value的反序列化方式
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      # 当服务端没有该消费者对应的offset时，该从哪开始读取消息
      auto-offset-reset: earliest
      # 消费者的offset是否在后台定期提交。(当获取消息后，无论是否抛出异常，都会提交当前消费的offset)。注意：设置为false时需配合ackMode,不然spring还是会自动提交
      enable-auto-commit: true
      # 如果“enable.auto.commit”设置为true ，则消费者偏移量自动提交给Kafka的频率。
      auto-commit-interval: 1000
    listener:
      # 提交模式。如果是手动提交,同时需要配置enable-auto-commit: false
#      ack-mode: manual
